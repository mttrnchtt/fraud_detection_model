LR_model:
  iterations: 1000
  learning_rate: 0.01
evaluation:
  alt_thresholds:
  - 0.1
  - 0.25
  - 0.5
  default_threshold: 0.5
  metrics:
  - auroc
  - auprc
  - accuracy
  - precision
  - recall
  - f1
  threshold_metric: f1
experiment:
  name: meta_tune_2
  seed: 1337
logging:
  log_interval: 20
  predictions_path: outputs/meta_mlp/preds
  save_config_copy: true
  save_predictions: true
model:
  activation: relu
  bias: true
  dropout:
  - 0.1
  - 0.0
  hidden_dims:
  - 16
  - 8
  input_dim: 8
  output_activation: sigmoid
  use_batchnorm: true
optimizer:
  betas:
  - 0.9
  - 0.999
  lr: 0.003
  name: adam
  weight_decay: 0.0001
paths:
  checkpoint_dir: models/meta_mlp
  output_dir: outputs/meta_mlp
  processed_dir: data_processed
  report: reports/meta_model.txt
  test_features: data_processed/X_test.npz
  test_labels: data_processed/y_test.npy
  train_features: data_processed/X_val.npz
  train_labels: data_processed/y_val.npy
scheduler:
  cooldown: 0
  factor: 0.5
  min_lr: 1.0e-06
  monitor: val_auprc
  name: reduce_on_plateau
  patience: 3
training:
  accumulate_steps: 1
  batch_size: 2048
  class_balance: true
  early_stopping:
    mode: max
    monitor: val_auprc
    patience: 8
  epochs: 100
  grad_clip: 1.0
  mixed_precision: false
  pos_weight: 518.7
